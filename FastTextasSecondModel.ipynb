{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a57e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext-wheel\n",
      "  Downloading fasttext_wheel-0.9.2-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "Collecting pybind11>=2.2 (from fasttext-wheel)\n",
      "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\vj24-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fasttext-wheel) (65.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vj24-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fasttext-wheel) (1.26.4)\n",
      "Downloading fasttext_wheel-0.9.2-cp310-cp310-win_amd64.whl (241 kB)\n",
      "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
      "Installing collected packages: pybind11, fasttext-wheel\n",
      "\n",
      "   ---------------------------------------- 0/2 [pybind11]\n",
      "   ---------------------------------------- 0/2 [pybind11]\n",
      "   ---------------------------------------- 0/2 [pybind11]\n",
      "   ---------------------------------------- 0/2 [pybind11]\n",
      "   -------------------- ------------------- 1/2 [fasttext-wheel]\n",
      "   ---------------------------------------- 2/2 [fasttext-wheel]\n",
      "\n",
      "Successfully installed fasttext-wheel-0.9.2 pybind11-2.13.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fasttext-wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f10d88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/cleanedDataSecondModel_merged.csv\")\n",
    "\n",
    "# Convert to fastText format\n",
    "def save_fasttext_format(df, filepath):\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        for text, label in zip(df['quote'], df['general_label']):\n",
    "            line = f\"__label__{label} {text.strip()}\\n\"\n",
    "            f.write(line)\n",
    "\n",
    "save_fasttext_format(df.sample(frac=0.8, random_state=42), \"datasets/FTtrain.txt\")\n",
    "save_fasttext_format(df.drop(df.sample(frac=0.8, random_state=42).index), \"datasets/FTtest.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c58cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.train_supervised(input=\"datasets/FTtrain.txt\", epoch=4, lr=1, wordNgrams=4, verbose=2)\n",
    "model.save_model(\"models/fasttext_model.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31462c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 0.84, 0.84)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"datasets/FTtest.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ea0e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: Other\n",
      "Confidence: 0.7860459089279175\n"
     ]
    }
   ],
   "source": [
    "quote = \"Success is not final, failure is not fatal\"\n",
    "label, prob = model.predict(quote)\n",
    "\n",
    "print(\"Predicted Category:\", label[0].replace(\"__label__\", \"\"))\n",
    "print(\"Confidence:\", prob[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29bc854b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Altruism       0.00      0.00      0.00        13\n",
      "     Learning       0.00      0.00      0.00        16\n",
      "        Other       0.61      1.00      0.75        46\n",
      "   Positivity       0.94      0.91      0.92        33\n",
      "Relationships       1.00      1.00      1.00        38\n",
      "         Self       1.00      1.00      1.00        54\n",
      "\n",
      "     accuracy                           0.84       200\n",
      "    macro avg       0.59      0.65      0.61       200\n",
      " weighted avg       0.75      0.84      0.79       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VJ24-1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\VJ24-1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\VJ24-1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "test_texts = []\n",
    "true_labels = []\n",
    "\n",
    "with open(\"datasets/FTtest.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\" \", 1)\n",
    "        if len(parts) == 2:\n",
    "            label, text = parts\n",
    "            test_texts.append(text)\n",
    "            true_labels.append(label.replace(\"__label__\", \"\"))\n",
    "\n",
    "\n",
    "predicted_labels = []\n",
    "\n",
    "for text in test_texts:\n",
    "    label, _ = model.predict(text)\n",
    "    predicted_labels.append(label[0].replace(\"__label__\", \"\"))\n",
    "\n",
    "\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
